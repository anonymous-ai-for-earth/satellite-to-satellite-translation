# Dataset
dataset: g16g17h8

# Paths
model_path: /nobackupp10/tvandal/unsupervised-spectral-synthesis/experiments/ICLR/G16G17H8_16-16-16-Skip-VISTIR ## where to save the model and checkpoints

data:
    G16:
        data_url: 'file:///nobackupp10/tvandal/data/petastorm/G16_64x64_2km-large/'
        bands: 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15
        shared: 
            G17: 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15
            H8: 0,1,2,4,5,6,7,8,9,10,11,12,13,14,15
        dim: 16
    G17:
        data_url: 'file:///nobackupp10/tvandal/data/petastorm/G17_64x64_2km-large/'
        bands: 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15
        shared: 
            G16: 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15
            H8: 0,1,2,4,5,6,7,8,9,10,11,12,13,14,15
        dim: 16
    H8:
        data_url: 'file:///nobackupp10/tvandal/data/petastorm/H8_64x64_2km-large/'
        bands: 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15
        shared: 
            G16: 0,2,3,4,5,6,7,8,9,10,11,12,13,14,15
            G17: 0,2,3,4,5,6,7,8,9,10,11,12,13,14,15
        dim: 16
        
# data options
num_workers: 8                  # number of data loading threads

# logger options
checkpoint_step: 5000      # How often do you want to save trained models
log_iter: 250                # How often do you want to log the training stats

# optimization options
max_iter: 200000             # maximum number of training iterations
batch_size: 8                # batch size
weight_decay: 0.0001          # weight decay
beta1: 0.5                    # Adam parameter
beta2: 0.999                  # Adam parameter
init: gaussian                # initialization [gaussian/kaiming/xavier/orthogonal]
lr: 0.0001                    # initial learning rate
step_size: 25000              # how often to decay learning rate
gamma: 0.5                    # how much to decay learning rate

# Loss weights
gan_w: 1                      # weight of adversarial loss
recon_x_w: 1                  # weight of image reconstruction loss
recon_h_w: 0                  # weight of hidden reconstruction loss
recon_kl_w: 0.01              # weight of KL loss for reconstruction
recon_x_cyc_w: 1              # weight of cycle consistency loss
recon_kl_cyc_w: 0.00          # weight of KL loss for cycle consistency
recon_z_cyc_w: 1
recon_shared_w: 0.1           # weight of shared reconstruction loss
cycle_step: 100000

# model options
gen:
  dim: 64                     # number of filters in the bottommost layer
  activ: lrelu                # activation function [relu/lrelu/prelu/selu/tanh]
  n_downsample: 0             # number of downsampling layers in content encoder
  n_res: 4                    # number of residual blocks in content encoder/decoder
  pad_type: zero              # padding type [zero/reflect]
  skip_connection: 0,7        # use this band as a skip connection [list ints]
dis:
  dim: 64                     # number of filters in the bottommost layer
  norm: none                  # normalization layer [none/bn/in/ln]
  activ: lrelu                # activation function [relu/lrelu/prelu/selu/tanh]
  n_layer: 2                  # number of layers in D
  gan_type: lsgan             # GAN loss [lsgan/nsgan]
  num_scales: 1               # number of scales
  pad_type: reflect           # padding type [zero/reflect]
